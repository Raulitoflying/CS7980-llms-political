# Political Stance Classification with LLMs

This repository contains code for experimenting with Large Language Models (LLMs) for political stance classification, comparing performance with and without user context.

## Project Overview

This project investigates how incorporating user context (in the form of user summaries) affects the ability of various LLMs to classify the political orientation of social media posts. We compare performance metrics across multiple state-of-the-art models including Claude 3.7 Sonnet, Llama 3.1, GPT-4o Mini, Mistral, Qwen, and Grok.

## Data Requirements

> **IMPORTANT:** To reproduce these experiments, you will need access to the original dataset (referenced as `posts_201908161514` in the code). This dataset is not included in this repository due to size and privacy considerations. Please contact **Professor Tony Mullen** to obtain the necessary data files.

The complete experiment workflow requires the following steps with their respective input/output files:

1. Filter unknown stance posts with `filterUnknownPosts.py`
2. Create user summaries with `createUserSummaries.py`
3. Run baseline classification with `stanceClassificationCode(noContext).py`
4. Run context-enhanced classification with `stanceClassificationCode(withContext).py`
5. Visualize and compare results with `visualazation.py`

## Files and Their Functions

- **createUserSummaries.py**: Generates political user summaries from user post histories, creating a condensed representation of each user's political orientation and posting patterns.

- **filterUnknownPosts.py**: Filters out posts with unknown political stances from the dataset, ensuring the evaluation focuses on classifiable content.

- **stanceClassificationCode(noContext).py**: Baseline classifier that predicts political stance of posts without any user context information.

- **stanceClassificationCode(withContext).py**: Enhanced classifier that incorporates user context (from summaries) when predicting political stance.

- **visualazation.py**: Creates visualizations comparing performance metrics between baseline and context-enhanced approaches across different models.

- **model_performance_comparison.csv**: Contains detailed metrics for each model's performance with and without context.

## Setup Instructions

### Prerequisites

- Python 3.8+
- OpenRouter API key (for accessing the LLMs)

### Installation

1. Clone this repository:
   ```
   git clone https://github.com/Raulitoflying/CS7980-llms-political.git
   cd CS7980-llms-political
   ```

2. Create a virtual environment (recommended):
   ```
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install required packages:
   ```
   pip install -r requirements.txt
   ```

4. Create a `.env` file in the project root and add your OpenRouter API key:
   ```
   OPENROUTER_API_KEY=your_api_key_here
   ```

## Running the Code

### Complete Workflow

To reproduce the full experiment, follow these steps in order:

### 1. Filter Unknown Posts

```
python filterUnknownPosts.py
```
This processes the original data and creates filtered datasets by removing posts with unknown political stances.

### 2. Generate User Summaries

```
python createUserSummaries.py
```
This analyzes user posting histories and creates political user summaries, saving them to `political_user_summaries.json`.

### 3. Run Classification Without Context

```
python "stanceClassificationCode(noContext).py"
```
You'll be prompted to enter an output directory where baseline results will be saved.

### 4. Run Classification With Context

```
python "stanceClassificationCode(withContext).py"
```
Similarly, you'll be prompted for an output directory for the enhanced results.

### 5. Visualize Results

```
python visualazation.py
```
This will generate visualizations comparing the performance of different models.

## Data Format

The code expects:
- A JSON file containing social media posts
- User summaries in the format generated by `createUserSummaries.py`

## Output

The code produces:
- JSON files with classification results for each model
- Visualizations comparing model performance
- CSV files with detailed metrics

## License

[Specify license]
